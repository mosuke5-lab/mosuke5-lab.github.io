<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Goldstine研究所</title>
    <link>https://blog.mosuke.tech/categories/linux/</link>
    <description>Recent content in Linux on Goldstine研究所</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 31 Jul 2015 21:15:00 +0900</lastBuildDate>
    
	<atom:link href="https://blog.mosuke.tech/categories/linux/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Packerやる前にKickstartはじめよう</title>
      <link>https://blog.mosuke.tech/entry/2015/07/31/211542/</link>
      <pubDate>Fri, 31 Jul 2015 21:15:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2015/07/31/211542/</guid>
      <description>1.はじめに
開発環境はVirualboxを使ったVagrantを利用しているが、
本番環境はAWSだったりKVMだったり違う仮想化機構で動作しているなんてことよくあると思います。
そういう環境下でどのように開発環境と本番環境の差分をなくしていますか？
わたしの場合、基本的にAnsibleを使ってプロビジョニングをしていますが、
そのプロビジョニング前のベースが異なってしまって困ることがよくあります。
一般に公開されているVagrantBox使ったら余計な設定が入っていたとか、すでにパッケージが入っていたとか…
そんな問題を解決しようとPackerを使おう！って考えました。
ですが、Packerも当たり前だけど魔法ではなく、Kickstartなどの自動インストールが前提なので、
Packerをやる前にKickstartを学習せよ、、、ということに気づきました。
ということでKickstartをはじめたよってことです。
2.kickstartってなに kickstartはOSのインストールを自動化する仕組みです。
anaconda社が提供するインストールの仕組みでRedhat系のOSが採用しているものです。
ですのでUbuntuだとPreseedっていう別の仕組みだそうです。（詳しくありませんっ）
で、Kickstartでなにができるかというと...
OSのインストールをしたことがある方ならわかるかと思いますが、
普通にDVDなどからインストールすると、
 言語はなににしますかー？ ホスト名なににしますかー？ パッケージはなにをいれますかー？  とか、聞かれて選択していく必要があります。 この作業を自動化できるのがkickstartです。
URLのようなもの。 はじめての自宅サーバ構築 - Fedora/CentOS - CentOS6 のインストール手順kajuhome.com
(おまけ)Ansible, Chef, Puppetとの違い？ kickstartにはプロビジョニング機能もついているため、
AnsibleとかChefとかPuppetとの違いは？住み分けは？と思うかもしれません。
明確に、住み分けが決まっているわけではありませんが、 個人的にはAnsibleやChefを実行する前の最低限の設定をkickstartにやらせようと思っています。
（一般的かとは思いますが…？）
Lee ThompsonのProvisioning Toolchainを参考にKiskstarのやる範囲をまとめると。 
Provisioning Toolchain: Web Performance and Operations - Velocity Online Conference - March 17, 2010 - O&#39;Reilly Mediaen.oreilly.com
3.Hello Kickstart!! Virtualboxを使ってKickstartを試しました。
3-1.用意したもの   Virtualbox  自分の環境はMacで、バージョンは5.</description>
    </item>
    
    <item>
      <title>Ansibleで最新のMySQLをインストールする際にハマったこと。MySQL-shared-compatのこと。</title>
      <link>https://blog.mosuke.tech/entry/2015/04/15/171127/</link>
      <pubDate>Wed, 15 Apr 2015 17:11:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2015/04/15/171127/</guid>
      <description>CentOS 6.5環境でAnsibleを使って最新のMySQLのセットアップをしようと思った際にハマったことをまとめた。
本質的にはAnsibleというよりLinux RPMパッケージのはなし。
ついでに、しょっぼいgithubを公開しました。
(1) 本記事を書くに至った経緯  Ansibleでmysqlを使ったサーバを構築(CentOS6.5)することになった。   MySQLのバージョンは5.6を採用した。    MySQLの公式rpmをダウンロードしインストールした。  インストールしたもの：MySQL-client, MySQL-devel, MySQL-server, MySQL-shared    MySQL-sharedをインストールする際にデフォルトのmysql-libsと競合  mysql-libsをアンインストールし再インストール AnsibleでMySQLの操作をするにはMySQL-pythonが必要なのでインストール  MySQL-pythonをインストールするにはさっきアンインストールしたmysql-libsが必要…(困った)  MySQL-shared-compatの存在に気づく 備忘録に書いておくか…  (2) MySQL-shared-compatの存在 mysql-libsは多くのパッケージの依存となっており、公式のMySQL5.6をインストールすることで、
他のパッケージがいれられない状況となっていた。
そんな状況を解決するためにMySQL-shared-compatというパッケージが用意されていた。
MySQL-shared-compatは「過去のMySQLバージョン向けの共有クライアントライブラリが納められているもの」だ。
詳細は下記参照をおすすめ。
MySQL-5.5.6から仕様が変わった「MySQL-shared-compat」の中身を徹底解剖 - Y-Ken Studio
ちなみに&#34;compat&#34;という単語がよく使われるが&#34;compatibility&#34;の略で「互換性」とかそういう意味。
(3) Githubで公開しました 内容は今のところ死ぬほど薄いのだが、MySQLをインストールするansibleを公開しました。 mosuke5/mysql-ansible · GitHub
内容はあれだが、特徴としては、インターネット上からRPMをダウンロードしてインストールする際に、
Ansibleでも「ダウンロード」→「インストール」の流れを踏む人が多いが、以下のようにするとシンプルになる。
varsでインストールしたいrpmやその取得先を記述しておいて、task側ではyumでnameにvarsで定義した変数を読むだけでできる。
role/mysql/vars/main.yml
mysql_url: http://ftp.jaist.ac.jp/pub/mysql/Downloads/MySQL-5.6 mysql_ver: &amp;quot;5.6.24-1&amp;quot; mysql_rpms: - MySQL-client-{{ mysql_ver }}.el6.x86_64.rpm - MySQL-shared-compat-{{ mysql_ver }}.el6.x86_64.rpm - MySQL-shared-{{ mysql_ver }}.</description>
    </item>
    
    <item>
      <title>SSHエージェントフォワード後に他のユーザでgit cloneする(鍵を使う)ことに関する考察</title>
      <link>https://blog.mosuke.tech/entry/2015/04/05/212518/</link>
      <pubDate>Sun, 05 Apr 2015 21:25:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2015/04/05/212518/</guid>
      <description>SSHのエージェントフォワードした後に、接続したユーザとは別のユーザでgit cloneしたいことがあった。
それについて調べていく中で学習したことや検討したことについてまとめた。
0. 前提 ローカルのPC(Mac)上で、Vagrantを使用してCentOS7の仮想サーバ(testsv)を立ち上げている。
&amp;lt;IPアドレス&amp;gt;
ローカルPC：192.168.33.1
仮想サーバ：192.168.33.100
本記事上での「git cloneする」とは、「プライベートのGitレポジトリからSSHを利用してクローンする」ということを指す。
1. SSHのエージェントフォワードを利用したい理由 まず、そもそもなぜSSHのエージェントフォワードをする必要があったのか。
最近では多くの方がご存知かつ利用していることだと思うが、仮想のサーバ上でgitを利用するときによく利用する。
(もちろんそれだけの用途ではありません)
仮想サーバを作るたびにSSHの鍵を生成して、Github等に登録するのが手間なので、
ローカルのPCの鍵を他のサーバへ引き継ぐことでgit clone等を可能にするのだ。
2. SSHエージェントフォワード利用時の挙動 SSHのエージェントフォワードで利用される認証情報は、接続先サーバの/tmp以下に保存されます。
[myuser@localpc ~]$ ssh -A vagrant@192.168.33.100 Last login: Sat Apr 4 xx:xx:xx 2015 from 192.168.33.1 [vagrant@testsv ~]$ [vagrant@testsv ~]$ ls -l /tmp | grep ssh drwx------. 2 vagrant vagrant 23 4月 4 11:35 ssh-skQVHsUCHU  
また、接続ユーザにはSSH_AUTH_SOCKという環境変数ができ、どの認証情報を利用するか記述がされます。
実際に確認してみる。
確認方法は、envコマンドで環境変数一覧を表示し、そのなかで&#34;ssh&#34;を含むものをgrep。
[vagrant@testsv ~]$ env | grep -i ssh SSH_AUTH_SOCK=/tmp/ssh-skQVHsUCHU/agent.9034 SSH_CLIENT=&#39;192.168.33.1 58017 22&#39; SSH_CONNECTION=&#39;192.</description>
    </item>
    
    <item>
      <title>Ruby, thin(bundler利用)を使った環境でのアプリの自動起動設定</title>
      <link>https://blog.mosuke.tech/entry/2015/02/22/211316/</link>
      <pubDate>Sun, 22 Feb 2015 21:13:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2015/02/22/211316/</guid>
      <description>bunlderを使ったWebアプリをプロダクション環境で動かすときに、アプリの起動をどうやって実現しているだろうか。
Apache Passengerを使う場合には、Apacheの起動がアプリの起動につながるので、 アプリの起動はあまり気にしなかったかもしれない。
しかし、例えばNginx × Unicorn/thinの構成などの場合はUnicornやthinの起動もしなければいけなくなってくる。
（あるいはこのようなケースがあるかは謎だが、Unicornやthinを単体で動かそうとしている場合など）
Unicornやthin（例ではthinを扱うが本質は同じ）の自動起動を実現する際の勘所、注意事項をまとめた。
0. 前提  CentOS6.5上でRubyでのWebアプリケーションを作っている。  アプリケーションサーバはthinを利用している。 また、gemパッケージ管理にbundlerを利用している。  1. 開発環境でよくするアプリの起動 開発環境では、アプリケーションのログの閲覧性なども兼ねて以下のようにアプリを起動していた。
$ bundle exec rackup $ bundle exec thin start  でも、これではいつまでたってもプロダクション環境での利用はできません。
2. 上記方法ではプロダクション環境で利用できない理由 当然のことながら、プロダクション環境ではいちいち手動でコマンドを実行しアプリケーションを立ち上げるわけにはいかない。
例えば、なんらかの理由でサーバが再起動してしまった場合には、
このままではアプリケーションが自動的に立ち上がらないため、サービスの停止につながってしまう。
ではどうするのか？
以下の状態であることがプロダクション環境では理想なのではないだろうか？
 オリジナルアプリケーションもserviceコマンドで起動・停止ができる  他のサービスと同様の操作方法が可能なのでわかりやすい   サーバ立ち上げ時にサービスが自動で起動される  3. 起動スクリプトを作ろう 上記の状態にもっていくためには、起動スクリプトを作らなければならない。
起動スクリプトを作る…！？
「作ったことないし、すぐには作れないよ〜」って思うかもしれないが、
サンプルはたくさんあるし、よく見てみるとそれほど難しくはない。
thinを使ったサンプルを探そうと思うと数は少ないが、Unicornも同じ仕組なので、 &#34;unicorn init script&#34;なんて検索をかけてもいろいろでてくるのでおすすめ。
参考ししたもの
https://gist.github.com/sbeam/3454488
上を参考にしながら、こんな起動スクリプトを作ってみた。（未完成版）
これを/etc/init.d以下へ配置する。
#!/bin/bash ### BEGIN CHKCONFIG INFO # chkconfig: 2345 55 25 # description: sample-app ### END CHKCONFIG INFO SCRIPT_NAME=/etc/init.</description>
    </item>
    
    <item>
      <title>スーパーサーバってなに？ xinetdでサービスを常駐起動せずに利用する</title>
      <link>https://blog.mosuke.tech/entry/2015/01/02/013658/</link>
      <pubDate>Fri, 02 Jan 2015 01:36:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2015/01/02/013658/</guid>
      <description>使用頻度の低いサービスのデーモンをメモリに常駐させておくのは効率が悪い。
そこでスーパーサーバという使用頻度の低いサービスの窓口のサービスのみ起動しておき、要求があったときだけ特定のサービスを起動させることが可能らしい。
ということで、そのスーパーサーバとやらを実際に触ってみた。
スーパーサーバというとinetdとxinetdがあるらしいが、
xinetdはinetdの拡張版で、アクセス制御などの機能を搭載しているとのこと。
今回はxinetdを設定してみる。
1. 事前準備 【環境】
Vagrantで構築したCentOS 6.5
(仮想環境のIPアドレスは192.168.33.10)
まずはスーパーサーバで管理するサービスを考えなければならない。
SSHとかhttpはどう考えてもスーパーサーバの管理するようなものではないだろうし…
FTPやtelnet、POP3なんかのサービスに利用されることが多いそう？（このへんよくわかない）
今回はFTPをスーパーサーバの管理対象とした。
※本来は複数のサービスを管理対象とするからこそ意味がある。
まずはxinetdとvsftpをインストール
$ sudo yum install xinetd vsftpd  
xinetdどうこうの前に、ftp接続がきちんとできるか確認するのでサービスを起動。
$ sudo service vsftpd start  
ローカルPCから接続できることを確認する。
$ ftp 192.168.33.10 Connected to 192.168.33.10. 220 (vsFTPd 2.2.2) Name (192.168.33.10:username):  2. xinetdの設定 xinetdの基本設定は/etc/xinetd.confにかかれており、
xinetdで管理する各サービスの設定は/etc/xinetd.d/配下に書く方式。
ftpの設定を以下の通りにした。
&#34;service&#34;のあとに書くサービス名称は/etc/servicesに定義されているものを記載する。
vsftpとか書いても動かないので注意。
$ sudo vim /etc/xinetd.d/ftp service ftp { disable = no socket_type = stream wait = no user = root server = /usr/sbin/vsftpd log_on_failure += USERID }  設定項目については以下参照。</description>
    </item>
    
    <item>
      <title>後からGitレポジトリを共有設定に。sharedオプションの仕組みについて</title>
      <link>https://blog.mosuke.tech/entry/2014/11/20/230334/</link>
      <pubDate>Thu, 20 Nov 2014 23:03:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2014/11/20/230334/</guid>
      <description>Gitレポジトリを作って、複数人で開発をしていた。
しかし、レポジトリの中に作成されるファイルやディレクトリが個人のグループになってしまい、
Push, PullするときにPermission errorで怒られまくる。
ユーザには共通のグループを作っていたのに…なんでだっけ…
気づけばレポジトリを作るとき以下のようにしていた。
$ git init --bare  複数人で共有するときには以下のようにするべきであった。
$ git init --bare --shared  では、そもそもgitのsharedオプションをつけると何が裏で起こっているのか。
調べると「setgid」というキーワードに辿り着いた。
setgidの権限を付けておくと、そのディレクトリに作成されたファイルの所有グループは、そのディレクトリの所有グループになる。
以下のようにchmodでsetgidを付けることができる。
$ chmod g+s dir_name  setgidがつくとあまり馴染みのない権限がつく。
「drwxrwsr-x」
$ ls -l drwxrwsr-x 4 user group 136 11 16 22:49 test_dir  そして、すでに共有設定なしで作ってしまったレポジトリでは以下のように対応可能。
（新しくレポジトリつくるのはめんどいので…）
##Gigレポジトリ内のディレクトリに $ chmod -R g+s ./branches $ chmod -R g+s ./hooks $ chmod -R g+s ./info $ chmod -R g+s ./objects $ chmod -R g+s .</description>
    </item>
    
    <item>
      <title>【VPS1台でインフラ勉強】HAProxyでロードバランサーを構築</title>
      <link>https://blog.mosuke.tech/entry/2014/11/09/171436/</link>
      <pubDate>Sun, 09 Nov 2014 17:14:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2014/11/09/171436/</guid>
      <description>前回の【VPS1台でインフラ勉強】サーバ複数台構成、Nginxでリバースプロキシ構築に続き、同様の環境を用いて、ロードバランサ構築を行った。
ロードバランサの構築にはHAProxyを利用した。
1. 環境 前回同様で、さくらVPSの1GBのプラン1台のみ。
・メモリ：１GB
・CPU：仮想２コア
・HDD：100GB
・OS：CentOS7
・サーバ仮想化：Vagrant(Utuntu13)
・ロードバランサ：HAProxy - The Reliable, High Performance TCP/HTTP Load Balancer
 2. 構成図 
 3. ロードバランサの構築 ■ホストサーバ側の設定
#HAProxyインストール $ sudo yum install haproxy #設定はすごく簡単で以下のファイルのみ。実際に $ sudo vim /etc/haproxy/haproxy.cfg #--------------------------------------------------------------------- # Example configuration for a possible web application. See the # full configuration options online. # # http://haproxy.1wt.eu/download/1.4/doc/configuration.txt # #--------------------------------------------------------------------- #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global log 127.0.0.1 local6 debug chroot /var/lib/haproxy pidfile /var/run/haproxy.</description>
    </item>
    
    <item>
      <title>【VPS1台でインフラ勉強】サーバ複数台構成、Nginxでリバースプロキシ構築</title>
      <link>https://blog.mosuke.tech/entry/2014/10/09/230555/</link>
      <pubDate>Thu, 09 Oct 2014 23:05:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2014/10/09/230555/</guid>
      <description>ロードバランシングとかクラスタリングとかリバースプロキシとか、
業務でも使っているし、概念とかはわかってるけど、自分で構築したことはやっぱりない。
自分で構築してみたいなーと思いつつもあたりまえだけど、サーバやネットワーク機器をそう簡単に調達もできない。
お金も当然ない。
というわけで、さくらVPSで仮想化つかってロードバランシングとかクラスタリングとかリバースプロキシとか勉強しましょうという「サーバインフラ会」を友人と始めた。
その第１回目のメモ。
第1回 サーバ複数台構成、Nginxでリバースプロキシ構築
第2回 HAProxyでロードバランサ構築


1. 使用した環境 まず今回利用した環境は以下のとおり。
さくらVPSの1GBのプラン。
・メモリ：１GB
・CPU：仮想２コア
・HDD：100GB
・OS：CentOS7
・仮想化：Vagrant
→dockerなどもはじめ検討していたが、コンテナ型仮想化だとサーバ感がでないので、よりサーバとして意識できるVagrantを採用
【参考】
料金・サービス仕様 | VPS（仮想専用サーバ）は「さくらのVPS」
 2. 完成イメージ・物理イメージ 

 
 3. VagrantでWebサーバ２台分を構築する Vagrantの詳細な利用方法は公式ドキュメントをみてもらうとするが、セットアップまでのひととおりの流れと注意点のみ記載する。
Vagrant Documentation
今回はWebサーバ２台を仮想で実現するので、それぞれweb1, web2とする。
それぞれのディレクトリを作成。
## web1, web2のディレクトリ作成 $ pwd /home/vagrant $ mkdir web1 $ mkdir web2 ## 仮想化で利用するOSイメージをダウンロード $ vagrant box add ubuntu1310 ¥ http://opscode-vm-bento.s3.amazonaws.com/vagrant/virtualbox/opscode_ubuntu-13.10_chef-provisionerless.box ## web1サーバ構築 $ cd web1 $ vagrant init ubuntu1310 ## ほぼほぼデフォルトの設定だが以下２つだけは設定を行った。 $ vim Vagrantfile # (1)プライベートアドレスの割り当て。 config.</description>
    </item>
    
    <item>
      <title>CentOS7, iptables設定でハマった</title>
      <link>https://blog.mosuke.tech/entry/2014/09/20/180326/</link>
      <pubDate>Sat, 20 Sep 2014 18:03:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2014/09/20/180326/</guid>
      <description>最近VPSのOSをcentos7にしたのだが、なかなか手付かずでiptablesの設定も放置していた…
（sshの最低限の設定はしていたが、ほんとうに良くない…）
久しぶりに手が空いたので設定するかーと思いきや
まず/etc/sysconfig/iptablesがないし&amp;hellip;
Cent7からのsystemctlでiptablesのサービスを確認してもでてこないし…
# systemctl status iptables iptables.service Loaded: not-found (Reason: No such file or directory) Active: inactive (dead)  というわけで、調べてみると、まずiptables.serviceをインスールしないといけないとのこと。
そして、centos7からはfirewalldがデフォルトでオンになっているからオフにしないといけない。
（いけないわけではないけど両方使う意味が無いので。）
まずはiptables-serviceをインスールし、firewalldをオフ、iptablesをオンとした。
# yum install iptables-services # systemctl status firewalld Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled) Active: active (running) since Sat 2014-09-20 17:47:11 JST; 4s ago Main PID: 11162 (firewalld) CGroup: /system.slice/firewalld.service └─11162 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid # # systemctl stop firewalld # # systemctl status firewalld Loaded: loaded (/usr/lib/systemd/system/firewalld.</description>
    </item>
    
  </channel>
</rss>