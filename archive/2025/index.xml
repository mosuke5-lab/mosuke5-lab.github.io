<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2025 on Goldstine研究所</title>
    <link>https://blog.mosuke.tech/archive/2025/</link>
    <description>Recent content in 2025 on Goldstine研究所</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 06 Dec 2025 00:00:50 +0900</lastBuildDate>
    <atom:link href="https://blog.mosuke.tech/archive/2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenShift LightspeedにMCPサーバーを追加して、AIエージェント機能を強化する</title>
      <link>https://blog.mosuke.tech/entry/2025/12/06/openshift-lightspeed-mcp/</link>
      <pubDate>Sat, 06 Dec 2025 00:00:50 +0900</pubDate>
      <guid>https://blog.mosuke.tech/entry/2025/12/06/openshift-lightspeed-mcp/</guid>
      <description>&lt;p&gt;こんにちは、もーすけです。&#xA;この記事は、&lt;a href=&#34;https://qiita.com/advent-calendar/2025/openshift&#34; target=&#34;_blank&#34;&gt;OpenShift Advent Calendar 2025&lt;/a&gt; の記事です。&lt;/p&gt;&#xA;&lt;p&gt;OpenShift LightspeedにMCP (Model Context Protocol) をインストールできる（まだDeveloper Previewですが）と知ったので、さっそく試してみました。&lt;/p&gt;&#xA;&lt;p&gt;MCPについては、以下のRed Hatの記事でも紹介されています。&lt;/p&gt;&#xA;&lt;div class=&#34;belg-link row&#34;&gt;&#xA;  &lt;div class=&#34;belg-left col-md-2 d-none d-md-block&#34;&gt;&#xA;    &lt;a href=&#34;https://developers.redhat.com/articles/2025/10/09/integrate-incident-detection-openshift-lightspeed-mcp&#34; target=&#34;_blank&#34;&gt;&#xA;      &lt;img class=&#34;belg-site-image&#34; src=&#34;https://developers.redhat.com/sites/default/files/styles/article_floated/public/figure2_26.png&#34; /&gt;&#xA;    &lt;/a&gt;&#xA;  &lt;/div&gt;&#xA;  &lt;div class=&#34;belg-right col-md-10&#34;&gt;&#xA;    &lt;div class=&#34;belg-title&#34;&gt;&#xA;      &lt;a href=&#34;https://developers.redhat.com/articles/2025/10/09/integrate-incident-detection-openshift-lightspeed-mcp&#34; target=&#34;_blank&#34;&gt;Integrate incident detection with OpenShift Lightspeed via MCP | Red Hat Developer&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;belg-description&#34;&gt;Learn how to integrate incident detection with OpenShift Lightspeed, the AI-powered virtual assistant for Red Hat OpenShift&lt;/div&gt;&#xA;    &lt;div class=&#34;belg-site&#34;&gt;&#xA;      &lt;span class=&#34;belg-site-name&#34;&gt;developers.redhat.com&lt;/span&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;今回は、記事のまま試すだけでは面白くないので、違うMCPサーバーを入れてみたいと思います。&#xA;利用するのは &lt;code&gt;kubernetes-mcp-server&lt;/code&gt; です。&lt;/p&gt;&#xA;&lt;div class=&#34;belg-link row&#34;&gt;&#xA;  &lt;div class=&#34;belg-left col-md-2 d-none d-md-block&#34;&gt;&#xA;    &lt;a href=&#34;https://github.com/containers/kubernetes-mcp-server&#34; target=&#34;_blank&#34;&gt;&#xA;      &lt;img class=&#34;belg-site-image&#34; src=&#34;https://github.githubassets.com/favicons/favicon.svg&#34; /&gt;&#xA;    &lt;/a&gt;&#xA;  &lt;/div&gt;&#xA;  &lt;div class=&#34;belg-right col-md-10&#34;&gt;&#xA;    &lt;div class=&#34;belg-title&#34;&gt;&#xA;      &lt;a href=&#34;https://github.com/containers/kubernetes-mcp-server&#34; target=&#34;_blank&#34;&gt;GitHub - containers/kubernetes-mcp-server: Model Context Protocol (MCP) server for Kubernetes and OpenShift&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;belg-description&#34;&gt;Model Context Protocol (MCP) server for Kubernetes and OpenShift - containers/kubernetes-mcp-server&lt;/div&gt;&#xA;    &lt;div class=&#34;belg-site&#34;&gt;&#xA;      &lt;img src=&#34;https://github.githubassets.com/favicons/favicon.svg&#34; class=&#34;belg-site-icon&#34;&gt;&#xA;      &lt;span class=&#34;belg-site-name&#34;&gt;GitHub&lt;/span&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Mac mini M4 Pro (64GB) はローカルLLMの夢を見るか？ パフォーマンス検証とAIエージェント連携の現実 </title>
      <link>https://blog.mosuke.tech/entry/2025/04/04/mac-mini-local-llm/</link>
      <pubDate>Fri, 04 Apr 2025 11:23:27 +0900</pubDate>
      <guid>https://blog.mosuke.tech/entry/2025/04/04/mac-mini-local-llm/</guid>
      <description>&lt;p&gt;こんにちは、もーすけです。&lt;br&gt;&#xA;昨今は、LLMの話題は尽きません。claudeやGeminiなどのクラウドLLMがすごいのはわかっていますが、 ローカルLLMがどこまでいけるのか、気軽に用意できるレベルでどこまでいけるのか、、、 とても気になっています。&lt;/p&gt;&#xA;&lt;p&gt;というわけで、新しいMac mini (M4 Pro, 64GBメモリ) を購入してみました！ Apple Silicon搭載Macは、その高い電力効率とユニファイドメモリによって、ローカル環境でのAI/機械学習タスク、特に大規模言語モデル（LLM）の実行において注目されています。&lt;/p&gt;&#xA;&lt;p&gt;今回は、この新しいMac miniでローカルLLMがどの程度実用的に動作するのか、いくつかのモデルサイズや量子化方式を比較しながら検証してみました。さらに、ローカルLLMをAIエージェント（Cline）と連携させて、少し複雑なタスクを実行できるかも試してみました。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
