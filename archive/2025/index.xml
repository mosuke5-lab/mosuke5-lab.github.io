<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2025 on Goldstine研究所</title>
    <link>https://blog.mosuke.tech/archive/2025/</link>
    <description>Recent content in 2025 on Goldstine研究所</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 13 Dec 2025 14:15:00 +0900</lastBuildDate>
    <atom:link href="https://blog.mosuke.tech/archive/2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>「変革の軌跡」を読んで考える、大規模組織がアジャイル変革で生き残るための「覚悟」</title>
      <link>https://blog.mosuke.tech/entry/2025/12/13/leading-the-transformation/</link>
      <pubDate>Sat, 13 Dec 2025 14:15:00 +0900</pubDate>
      <guid>https://blog.mosuke.tech/entry/2025/12/13/leading-the-transformation/</guid>
      <description>&lt;p&gt;こんにちは、もーすけです。&#xA;本日は、大規模組織におけるアジャイル・DevOps変革のバイブルとも言える一冊、「&lt;a href=&#34;https://amzn.to/3XO8X2V&#34;&gt;変革の軌跡 ー世界で戦える会社に変わるアジャイル・DevOps導入の原則ー&lt;/a&gt;」を紹介します。&lt;/p&gt;&#xA;&lt;p&gt;この本は、単なるキラキラしたアジャイルの導入事例集ではありません。&lt;strong&gt;数百・数千人のエンジニアを抱える「古くからある大企業」が、いかにしてスタートアップのような開発スピードと柔軟性を手に入れるか&lt;/strong&gt;、その原則と実践が記された、極めて実践的で、そして少し痛みも伴うドキュメントです。&lt;/p&gt;&#xA;&lt;p&gt;私自身、多くの企業のDevOps支援に関わる中で、「現場でアジャイルを始めたけれど、組織全体が変わらない」「PoC（概念実証）はうまくいったのに、全社展開で頓挫した」という声を嫌というほど聞いてきました。&#xA;そうした悩みを持つ方、特にエンタープライズ領域で戦っているリーダーにとって、本書は現状を打破する強力な武器になるはずです。&lt;/p&gt;&#xA;&lt;div class=&#34;belg-link row&#34;&gt;&#xA;  &lt;div class=&#34;belg-left col-md-2 d-none d-md-block&#34;&gt;&#xA;    &lt;a href=&#34;https://amzn.to/3XO8X2V&#34; target=&#34;_blank&#34;&gt;&#xA;      &lt;img class=&#34;belg-site-image&#34; src=&#34;https://m.media-amazon.com/images/I/71IbZx3psVL._SY522_.jpg&#34; /&gt;&#xA;    &lt;/a&gt;&#xA;  &lt;/div&gt;&#xA;  &lt;div class=&#34;belg-right col-md-10&#34;&gt;&#xA;    &lt;div class=&#34;belg-title&#34;&gt;&#xA;      &lt;a href=&#34;https://amzn.to/3XO8X2V&#34; target=&#34;_blank&#34;&gt;変革の軌跡 ー世界で戦える会社に変わるアジャイル・DevOps導入の原則ー&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;belg-description&#34;&gt;4500万ドルの開発費用の削減。サポートする製品数が140%増加。イノベーションのためのキャパシティが8倍に増加。これらは著者の2人がある企業のソフトウェア開発に変革をもたらした結果である。&lt;/div&gt;&#xA;    &lt;div class=&#34;belg-site&#34;&gt;&#xA;      &lt;span class=&#34;belg-site-name&#34;&gt;Amazon.co.jp&lt;/span&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>OpenShift LightspeedにMCPサーバーを追加して、AIエージェント機能を強化する</title>
      <link>https://blog.mosuke.tech/entry/2025/12/06/openshift-lightspeed-mcp/</link>
      <pubDate>Sat, 06 Dec 2025 00:00:50 +0900</pubDate>
      <guid>https://blog.mosuke.tech/entry/2025/12/06/openshift-lightspeed-mcp/</guid>
      <description>&lt;p&gt;こんにちは、もーすけです。&#xA;この記事は、&lt;a href=&#34;https://qiita.com/advent-calendar/2025/openshift&#34; target=&#34;_blank&#34;&gt;OpenShift Advent Calendar 2025&lt;/a&gt; の記事です。&lt;/p&gt;&#xA;&lt;p&gt;OpenShift LightspeedにMCP (Model Context Protocol) をインストールできる（まだDeveloper Previewですが）と知ったので、さっそく試してみました。&lt;/p&gt;&#xA;&lt;p&gt;MCPについては、以下のRed Hatの記事でも紹介されています。&lt;/p&gt;&#xA;&lt;div class=&#34;belg-link row&#34;&gt;&#xA;  &lt;div class=&#34;belg-left col-md-2 d-none d-md-block&#34;&gt;&#xA;    &lt;a href=&#34;https://developers.redhat.com/articles/2025/10/09/integrate-incident-detection-openshift-lightspeed-mcp&#34; target=&#34;_blank&#34;&gt;&#xA;      &lt;img class=&#34;belg-site-image&#34; src=&#34;https://developers.redhat.com/sites/default/files/styles/article_floated/public/figure2_26.png&#34; /&gt;&#xA;    &lt;/a&gt;&#xA;  &lt;/div&gt;&#xA;  &lt;div class=&#34;belg-right col-md-10&#34;&gt;&#xA;    &lt;div class=&#34;belg-title&#34;&gt;&#xA;      &lt;a href=&#34;https://developers.redhat.com/articles/2025/10/09/integrate-incident-detection-openshift-lightspeed-mcp&#34; target=&#34;_blank&#34;&gt;Integrate incident detection with OpenShift Lightspeed via MCP | Red Hat Developer&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;belg-description&#34;&gt;Learn how to integrate incident detection with OpenShift Lightspeed, the AI-powered virtual assistant for Red Hat OpenShift&lt;/div&gt;&#xA;    &lt;div class=&#34;belg-site&#34;&gt;&#xA;      &lt;span class=&#34;belg-site-name&#34;&gt;developers.redhat.com&lt;/span&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;今回は、記事のまま試すだけでは面白くないので、違うMCPサーバーを入れてみたいと思います。&#xA;利用するのは &lt;code&gt;kubernetes-mcp-server&lt;/code&gt; です。&lt;/p&gt;&#xA;&lt;div class=&#34;belg-link row&#34;&gt;&#xA;  &lt;div class=&#34;belg-left col-md-2 d-none d-md-block&#34;&gt;&#xA;    &lt;a href=&#34;https://github.com/containers/kubernetes-mcp-server&#34; target=&#34;_blank&#34;&gt;&#xA;      &lt;img class=&#34;belg-site-image&#34; src=&#34;https://github.githubassets.com/favicons/favicon.svg&#34; /&gt;&#xA;    &lt;/a&gt;&#xA;  &lt;/div&gt;&#xA;  &lt;div class=&#34;belg-right col-md-10&#34;&gt;&#xA;    &lt;div class=&#34;belg-title&#34;&gt;&#xA;      &lt;a href=&#34;https://github.com/containers/kubernetes-mcp-server&#34; target=&#34;_blank&#34;&gt;GitHub - containers/kubernetes-mcp-server: Model Context Protocol (MCP) server for Kubernetes and OpenShift&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;belg-description&#34;&gt;Model Context Protocol (MCP) server for Kubernetes and OpenShift - containers/kubernetes-mcp-server&lt;/div&gt;&#xA;    &lt;div class=&#34;belg-site&#34;&gt;&#xA;      &lt;img src=&#34;https://github.githubassets.com/favicons/favicon.svg&#34; class=&#34;belg-site-icon&#34;&gt;&#xA;      &lt;span class=&#34;belg-site-name&#34;&gt;GitHub&lt;/span&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Mac mini M4 Pro (64GB) はローカルLLMの夢を見るか？ パフォーマンス検証とAIエージェント連携の現実 </title>
      <link>https://blog.mosuke.tech/entry/2025/04/04/mac-mini-local-llm/</link>
      <pubDate>Fri, 04 Apr 2025 11:23:27 +0900</pubDate>
      <guid>https://blog.mosuke.tech/entry/2025/04/04/mac-mini-local-llm/</guid>
      <description>&lt;p&gt;こんにちは、もーすけです。&lt;br&gt;&#xA;昨今は、LLMの話題は尽きません。claudeやGeminiなどのクラウドLLMがすごいのはわかっていますが、 ローカルLLMがどこまでいけるのか、気軽に用意できるレベルでどこまでいけるのか、、、 とても気になっています。&lt;/p&gt;&#xA;&lt;p&gt;というわけで、新しいMac mini (M4 Pro, 64GBメモリ) を購入してみました！ Apple Silicon搭載Macは、その高い電力効率とユニファイドメモリによって、ローカル環境でのAI/機械学習タスク、特に大規模言語モデル（LLM）の実行において注目されています。&lt;/p&gt;&#xA;&lt;p&gt;今回は、この新しいMac miniでローカルLLMがどの程度実用的に動作するのか、いくつかのモデルサイズや量子化方式を比較しながら検証してみました。さらに、ローカルLLMをAIエージェント（Cline）と連携させて、少し複雑なタスクを実行できるかも試してみました。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
