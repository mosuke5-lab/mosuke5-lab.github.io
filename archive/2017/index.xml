<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2017 on Goldstine研究所</title>
    <link>https://blog.mosuke.tech/archive/2017/</link>
    <description>Recent content in 2017 on Goldstine研究所</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 01 Jul 2017 15:18:00 +0900</lastBuildDate>
    
	<atom:link href="https://blog.mosuke.tech/archive/2017/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>YAPC::Fukuoka前夜祭でLTしてきた。「Rancherでマルチクラウドをやってみる」</title>
      <link>https://blog.mosuke.tech/entry/2017/07/01/yapc_fukuoka/</link>
      <pubDate>Sat, 01 Jul 2017 15:18:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/07/01/yapc_fukuoka/</guid>
      <description>YAPC::Fukuokaに参加してきた。
今回は前夜祭にも参加してLTもしてきたので報告する。
「本当に最適なインフラ選べてる？Rancherでマルチクラウドをやってみる（超入門編）」
 登壇 実は、前夜祭ではなくてYAPC本体のほうで20分枠のスピーカを応募していたが、まあ流石に選考は通らず、 でもせっかく福岡に行くからには！ということで前夜祭のLTを申し込むことにした。 LTでは、Rancherを使ったマルチクラウドの考え方を話した。
いま自分はAlibaba Cloudの日本リージョンの運営とか日本での宣伝を仕事としてやっているが、 個人的な活動としてAlibabaCloudを表に出したのは初めてだった。
ただ、AlibabaCloudの宣伝だけするのはしたくなくって、 まだまだ日本で考え方が浸透していない「マルチクラウド」をキーワードにした。
僕自身、最近Rancherというコンテナのオーケストレーションツールと出会って、 マルチクラウドがこれからもっと流行っていくのではと感じた。
RancherをネタについでにAlibabaCloudも知ってもらえれば～というモチベーション。
ネタ話 福岡に来るときのフライトをなんと寝坊で逃した。
これはLTたのネタのためじゃないぞ！！？
けど、結果的にネタになったので良かったんじゃないかと思っている。
フライト逃してどうやって福岡に来たの？？
いろいろあったんですが…
はじめ振替できず、仕方なく新規にチケットを買おうと思ったら、なぜか券売機が故障したのもあって、
いろいろごたごたあって、振替をしてくれました。
魔法がかかりました（笑）
続きの話 今回は、マルチクラウドという考え方があるというところ、Rancherというものがどういうものか紹介するLTだった。
もうちょっと踏み込んだ話でどうやってマルチクラウドやっていくか、という続きの話をどこかでしたいと思っている。（というか準備中。）
MasterCloud(7月12日)で話せればなー…と思ってます。 https://mastercloud.connpass.com/event/59832/
さいごに LTは楽しい。福岡は飯がうまい。福岡、最高。</description>
    </item>
    
    <item>
      <title>Hugo、PageSpeed対策で自動で画像を圧縮する</title>
      <link>https://blog.mosuke.tech/entry/2017/06/12/hugo_optimize_image/</link>
      <pubDate>Mon, 12 Jun 2017 23:33:12 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/06/12/hugo_optimize_image/</guid>
      <description> はじめに 最近Hugoを使ったブログに移転した。
「はてなブログからHugoに移行。その際に行ったあれこれ。」
せっかくブログを運営するからにはSEOも少しがんばりたい。
PageSpeedで画像を最適化できるよっていわれたので、画像を圧縮させようと思った。
しかし、気がつくと忘れてしまったりするので、
Werckerを使って自動で最適化させることにした。
WerckerでのCI/CD環境 まず、Werckerを使ったCI/CD環境だが、こちらを参考にしてほしい。
「Werckerを使ってHugo+Github PagesのCI/CD環境を整備する」
画像圧縮処理 ブログの中で使う画像は、JPEGとPNGが混じっている。
そのため、両方に対応して画像を圧縮する必要があった。
画像の圧縮ツールはPageSpeedが推奨してきた、
optipngとjpegtranを利用することにした。
 OptiPNG: Advanced PNG Optimizer jpegtran  処理自体はいたってシンプル。
次のシェル(optimize_image.sh)を用意した。
#!/bin/sh find ./static/image/ -name &amp;quot;*.png&amp;quot; | xargs optipng -o5 find ./static/image/ -name &amp;quot;*.jpg&amp;quot; -type f -exec jpegtran -copy none -optimize -outfile {} {} \;  Werckerに組み込む wercker.ymlのbuildの段階で最適化を仕込めばおわり。
ただし、すべての画像ファイルをデプロイのたびに最適化すると時間がかかる。
定期的にローカルで圧縮してgitに更新しておいたほうがいいだろう。
あくまで、忘れてしまった時のためにCIでまかなってくれるというスタンスで利用している。
- script: name: optimize image size code: | sh ./scripts/optimize_image.sh  </description>
    </item>
    
    <item>
      <title>Werckerを使ってHugo&#43;Github PagesのCI/CD環境を整備する</title>
      <link>https://blog.mosuke.tech/entry/2017/06/04/hugo_deployment_with_wercker/</link>
      <pubDate>Sun, 04 Jun 2017 14:47:15 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/06/04/hugo_deployment_with_wercker/</guid>
      <description>以前、はてなブログからHugoを使ったサイトに移行したことを書いた。
こちら参照：はてなブログからHugoに移行。その際に行ったあれこれ。
今回、Hugoで記事を更新してからデプロイまでの流れをWerckerを使って自動化したので紹介する。
概要 今までは下記のフローでデプロイを行っていた。
一部シェルスクリプトにして自動化していたが、hugoファイルを管理するレポジトリとGithub Pages用の
２つのレポジトリへのコミットが必要で手間がかかっていた。
 hugoファイル側で記事更新、デザイン変更 更新のコミット、プッシュ hugoコマンドでビルド /public以下のファイルをgithub pages用のレポジトリへコピー github pages用レポジトリーへ移動してコミット、プッシュ CloudFlareのキャッシュ削除  このフローをWerckerを利用して下記のように変更した。
 hugoファイル側で記事更新、デザイン変更 更新のコミット、プッシュ Werckerでビルド Werckerでビルド結果をGithub pages用レポジトリへプッシュ WerckerでCloudFlareのキャッシュ削除やSlack通知  Werckerを使っていわゆるCI/CDのフローを組むことで、
hugo側のファイル・レポジトリ管理をするだけでよくなった。
werckerの設定 wercker.yml まず、wercker.ymlから記述する。
Werckerを利用するには自分のレポジトリにwercker.ymlを配置する必要があり、
このファイルに記述のとおりに自動化処理を行わせる。
本記事ではWerckerの細かい話は割愛するが、以下がwercker.ymlだ。
box: debian build: steps: - install-packages: packages: git - script: name: download theme code: | $(git clone https://github.com/dplesca/purehugo ./themes/purehugo) - arjen/hugo-build: version: &amp;quot;0.20&amp;quot; theme: purehugo flags: --buildDrafts=false after-steps: - slack-notifier: channel: $SLACK_CHANNEL url: $SLACK_URL username: wercker_bot deploy: steps: - install-packages: packages: git ssh-client curl - leipert/git-push: gh_oauth: $GIT_TOKEN repo: mosuke5-lab/mosuke5-lab.</description>
    </item>
    
    <item>
      <title>AWS Summit2017 Day2のぞいてきた。 ネットワーク設計入門メモ</title>
      <link>https://blog.mosuke.tech/entry/2017/05/31/aws_summit_network/</link>
      <pubDate>Wed, 31 May 2017 19:25:20 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/05/31/aws_summit_network/</guid>
      <description>はじめに 弊社はプレミアムフライデー導入企業なのだが、最終金曜日に早く帰る必要はなく、月内でどこか1日15時に帰りましょうという制度になっている。
金曜日が仕事の都合上取れなかったので、今月は5/31にプレミアムフライデー（プレミアムウェンズデー）を使った。
ちょうどAWS Summit開催中だったのでのぞきにいった。
雰囲気 想像していた雰囲気とはだいぶ異なっていたというのが第一印象。
想像以上にスーツの年齢層の高い人が多かった。それだけ、AWSもエンタープライズでも注目されるようになったということだろう。
以前に、JAWS2015に参加したことある。もちろんJAWSとAWS Summitでは参加者の層が違う。
が、あれから2年たちAWSに興味を持つ層も大きく変わってきたのを感じた。
セッションも非IT企業への導入事例や、思ったより入門セッションも多かった。
登壇者の話しぶりも「オンプレからの移行」を意識したように感じた。
ブース セッションだけではなく、AWSに関連するサービスを提供している企業がたくさんブースをだしている。
ここでのコミュニケーションが案外一番楽しい。お酒も用意されていて楽しくおしゃべりできた。
Heroku+AWSの組み合わせで利用するケースの話を聞いて、あーなるほどねって感じだった。
HerokuはAWS上で動作しているし、インターネット経由してもそこまで遅くはならない。
そんな利点を使って組み合わせて使う事例なんかきいた。
そのほかは、やっぱりどこもかしこもコンテナ。
コンテナをどう扱うか、どう監視するか、そんなところの話が多かった。
セッション「ネットワーク設計入門」 セッションは１つだけ「ネットワーク設計入門」を聞いた。
普段ならネットワーク設計入門のセッションは聞かないと思っているのだが、
どんなことを話すのか興味あって聞いてみた。
(1)クラウド上のNWの特徴  物理設計はいらない 可用性はすでにセット(VRRPなど気にしなくてよい） プロフラマブルに操作可能  (2)NWサービス NWサービスは意外とすくない。VPCがほぼすべて。
VPCが本質であり、ここが理解できればほぼ問題ない。
 VPC Direct Connect Route53  (3)前提知識 VPC 物理設計はいらないんだけど、
やっぱり物理知っていることがアドバンテージになる。 VPCはリージョンの中のみ。ゾーンはまたぐことができる。
専用線 当たり前だがDCの場所は公開していない。
じゃどうやって接続するか？
相互接続接続ポイントを用意しているからそこにつなぎに来てね、という考え方。
エッジロケーション CDNノードやRoute53が動作しているところ。
リージョンとはまた別にある。
(4)設計をはじめよう AWSのどのサービスを使いたいかでNWの設計方針はかわる。
まずはVPCの中で利用するサービスとVPCの外で使うものがあるのでその区別。
 VPCの中で使うもの  EC2とかRDSとかRedshift、EMR  VPCの外で使うもの  S3、LamdaとかDynamoDB、CloudWatch   次に、外部通信の設計
 VPCと外部を接続する場合  専用線orインターネットVPNorパブリック(ssh/https)  VPCがないけど外部から利用したい場合  httpsでまかなう場合が多い。 実は、VPCがなくてもDicrectConnectは使えるよ。  DirectConnectのパブリック接続    (5)プライベートNW設計のステップ  VPCの作成  VPCのCIDRレンジは変えられないから大きくとっておこう オンプレミスとのレンジも被らないように /16がおすすめ  サブネット作成  インターネットに接続するものとしないもの。ここでサブネット分けよう AZが落ちてもいいように設計しよう。サブネットは２つずつ サブネットサイズは24がおすすめ  VPCコンポーネントの作成  カスタマーGW インターネットGW VPC単位、サブネット単位、インスタンス単位で配置できるコンポーネントがあるよ  インスタンスの配置  セキュリティポリシーを考えよう セキュリティグループとネットワークACLがあるよ セキュリティグループのほうが柔軟  名前解決の検討  (6)ユースケースごとのNW設計 公開サービスの場合  インターネットから接続でいるのはロードバランサーだけにしよう  あるいはあとはメンテナンス用の踏み台サーバだけ  S3を活用するときは、VPCエンドポイントつかえばVPC内部から接続できるよ 管理拠点とはVPNでつなぐことをおすすめするよ 管理拠点とのルーティングはルートテーブル DNSはRoute53使うと便利だよ  ALIASレコードという独自機能 DNSのフェイルオーバー機能  ソーリーページへの転送が可能    社内システム基盤の場合  DirectConnectを使おう  パートナーがたくさんいるので連絡してみよう  Route53はプライベートゾーン、オンプレからVPC内の名前解決にも使えるよ DirectConnect体験ラボあるからつかってみて  https://aws.</description>
    </item>
    
    <item>
      <title>CloudFlare APIを使ってキャッシュを削除する</title>
      <link>https://blog.mosuke.tech/entry/2017/05/29/how_to_use_cloudflare_api/</link>
      <pubDate>Mon, 29 May 2017 20:06:31 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/05/29/how_to_use_cloudflare_api/</guid>
      <description>はじめに 最近ブログをはてなブログからHugoへ移行した。
HugoのフロントにCloudFlareを利用している。
ブログ移行についてはこちらを参照。
「はてなブログからHugoに移行。その際に行ったあれこれ。」
コンテンツをアップロードした場合などにCloudFlareのキャッシュを削除したく、
APIを利用して効率よく作業できる環境を整えた。
使い方 CloudFlareのAPIドキュメントはかなり充実している。
キャッシュの全削除については下記に記載がある。
https://api.cloudflare.com/#zone-purge-all-files
利用方法をみると、DELETE /zones/:identifier/purge_cacheとあるが、
:identifierがなんのことかはじめわからずはじめ苦戦した。
identifierの確認 identifierは下記APIで確認できる。
このAPIで返ってくるはじめのidがidenitiferだ。
curl -X GET &amp;quot;https://api.cloudflare.com/client/v4/zones \ ?name=&amp;lt;your site&amp;gt; \ &amp;amp;status=active \ &amp;amp;page=1 \ &amp;amp;per_page=20 \ &amp;amp;order=status \ &amp;amp;direction=desc \ &amp;amp;match=all&amp;quot; \ -H &amp;quot;X-Auth-Email: &amp;lt;your email&amp;gt;&amp;quot; \ -H &amp;quot;X-Auth-Key: &amp;lt;your api key&amp;gt;&amp;quot; \ -H &amp;quot;Content-Type: application/json&amp;quot;  { &amp;quot;result&amp;quot;: [ { &amp;quot;id&amp;quot;: &amp;quot;xxxxxxxxxxxxxxxxxxxxxxx&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;mosuke.tech&amp;quot;, &amp;quot;status&amp;quot;: &amp;quot;active&amp;quot;, &amp;quot;paused&amp;quot;: false, &amp;quot;type&amp;quot;: &amp;quot;full&amp;quot;, &amp;quot;development_mode&amp;quot;: 0, &amp;quot;name_servers&amp;quot;: [ &amp;quot;rudy.</description>
    </item>
    
    <item>
      <title>はてなブログからHugoに移行。その際に行ったあれこれ。</title>
      <link>https://blog.mosuke.tech/entry/2017/05/28/blog_migration/</link>
      <pubDate>Sun, 28 May 2017 13:02:14 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/05/28/blog_migration/</guid>
      <description>1.はじめに 2017年5月27日に2014年2月から約3年3ヶ月程度使ってきたはてなブログからHugoを使ったブログへ移行をした。
長らく使いやすいブログを提供してきたはてなさんにはとても感謝している。
はてなブログはとても魅力なブログプラットフォームであると感じているし、いまでもそう思うのだけれどいくつかの判断をした結果Hugoへの移行を決めた。
本記事では、移行を決めた理由や移行する際に行ったこと、Hugoの実行環境などを紹介する。
2.Hugoに移行した理由 Hugoに移行した理由というか、はてなブログから別のところに移行しようとした理由になるのだが、
端的に言うと以下のとおりだ。
 常時SSL化したかった HTTP/2に対応したかった 独自ドメイン(mosuke.tech)を利用したかった  Hugo以外にももちろん他のツールやサイトも検討を行った。
 はてなブログPro jekyll medium  まず、はてなブログProだが、もっとも手間がかからず独自ドメイン利用もできてよかったのだが、
SSL化とHTTP/2化はやはり難しかったので外部を検討した。
次にGithub製のJelyllだが、Github Pagesとの相性もよくはじめに検討はじめたものだった。
Ruby製ということもあり、自分に馴染みのあるツールで最有力候補だった。
しかし、後発のHugoの完成度の高さ、コンパイルの速さ、気に入ったテンプレートがあった、という理由でHugoに劣った。
最後にmediumだが、自前で構築することなくやりたいことのすべてを実現していた。
正直一番いいのではないかとも思う（笑）
最終的には、よりカスタマイズ度の高いHugoを選んだ。特にこれといった理由はない。
ちょうどGo言語をやってみたいモチベーションがあったので、これをきっかけに勉強がはかどればいいなぁくらいの気持ちはあった。
3.移行に際して行ったこと 3-1.Hugoでのサイト構築、アーキテクチャ Github上でHugoを管理し、コンパイルしてできたPublicファイルを、Github Pages対応の別のレポジトリで管理。
独自ドメイン利用、SSL対応、HTTP/2対応するためにフロントにCloudFlareを利用した。
後述するが、CloudFlareはとても便利なツールだが、キャッシュの扱いは気をつけてなければいけない。
図にすると以下のとおりだ。
3-2.記事の移行 はてなブログはそのままのこし、新規に書くブログからHugoへ移行することも検討したが、
せっかくなのではてなブログ時代に書いた記事もすべて移行することを決めた。
はてなブログからデータのエクスポートができる。
エクスポートしたファイルを簡単なスクリプトを作ってHugoファイルへの変換を行った。（Github mosuke5/hatena-blog-parser）
正直このツールは汎用的なものではない。このスクリプトだけではうまく行かない部分も多数ある。
いくぶんかsedなど使って（たまに手動編集・・・）して整えた。。
はてなブログのエクスポートファイルのフォーマット -------- AUTHOR: mosuke5 TITLE: 万能じゃない。オブジェクトストレージの仕組みと利用を正しく理解する BASENAME: 2017/03/18/182252 STATUS: Publish ALLOW COMMENTS: 1 CONVERT BREAKS: 0 DATE: 03/18/2017 18:22:52 CATEGORY: オブジェクトストレージ CATEGORY: ObjectStorage CATEGORY: クラウド CATEGORY: S3 IMAGE: https://cdn-ak.</description>
    </item>
    
    <item>
      <title>(備忘録) 運用サイトのドメインとサーバ</title>
      <link>https://blog.mosuke.tech/entry/2017/04/23/154957/</link>
      <pubDate>Sun, 23 Apr 2017 15:49:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/04/23/154957/</guid>
      <description>完全備忘録。自分でもわからなくなってきたので。 公開すればきっと更新もする。
docs.google.com</description>
    </item>
    
    <item>
      <title>万能じゃない。オブジェクトストレージの仕組みと利用を正しく理解する</title>
      <link>https://blog.mosuke.tech/entry/2017/03/18/182252/</link>
      <pubDate>Sat, 18 Mar 2017 18:22:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/03/18/182252/</guid>
      <description>1.はじめに
Amazon S3をはじめとして、オブジェクトストレージが身近になってきています。
各クラウドベンダーはオブジェクトストレージサービスを提供しています。
 Amazon S3 Azure Blob Storage Google Cloud Storage Alibaba Cloud OSS Cloud n ObjectStorage IDCF オブジェクトストレージ  ですが、オブジェクトストレージをストレージの魔法として理解されているケースも多いように感じます。
原点に振り返ってそもそもオブジェクトストレージとはなんなのか。
どんな特徴を持っているストレージなのか。
気になってまとめました。
2.オブジェクトストレージとは オブジェクトストレージとは一言で言うと、
「オブジェクト単位（ファイル単位）で出し入れのできる、ネットワークストレージ」です。
オブジェクトストレージでは直接にストレージ上のファイルをRead/Writeすることはできません。
いうなれば、FTPサーバに近い存在と言えます。
今やクラウド上のストレージの代名詞として扱われるオブジェクトストレージですが、
実はファイルの出し入れしかできないストレージなのです！？！？
3.特徴 では、そんな出し入れしかできないFTPサーバに似たオブジェクトストレージですが、
その本当の特徴はどこにあるのでしょうか。
特徴1: ディレクリ構造の排除 1つ目の特徴としては、ディレクトリ構造でファイルを管理しないことです。
ディレクトリ構造は、もしストレージサーバのハードディスク容量がいっぱいになり、
ファイルを別のディスクに移動する場合、そのディレクトリパスも変更しなければいけません。
クラウドサービスのようなたくさんのユーザが利用し拡張性の求められる場面では、ディレクトリ構造は適さないのです。
そこで、オブジェクトストレージではディレクトリ構造ではなく、階層のないフラットな関係でファイルが保存されます。
すべてのファイルにIDが付与され、そのIDがどこに保管されているか別で管理する仕組みとなっています。
特徴2: 分散保存 2つ目の特徴は「分散保存」です。
オブジェクトストレージでは、ファイルを分散保存するアーキテクチャによって、
ファイルの冗長化と大量のファイルへのアクセスさばくことを可能にしています。
詳しくは次の「オブジェクトストレージのアーキテクチャ」の項目でご紹介します。
特徴3: アプリケーションからの利用を意識 3つ目の特徴はアプリケーションでの利用を強く意識していることです。
この項目は製品によって異なる部分もありますが、主な点を３つあげます。
(1)メタ情報管理 従来のファイルシステムでのファイルへのメタ情報は、ファイルのサイズや更新日付などが一般的でした。
オブジェクトストレージでは更にファイルの有効期限などを設定することができ、インフラ管理を容易にします。
(2)HTTPプロトコルを使ったインターフェイス  オブジェクトストレージでは、ファイルのアップロード、ダウンロードなどすべての操作はHTTPプロトコルを利用します。
HTTPのような汎用的なプロトコルを採用することにより、サーバからはもちろん、モバイル端末など幅広いデバイスから利用が可能です。
(3)Web公開機能 更には、保存したオブジェクトに対してURLを割り当てて公開することもできます。
静的なWebサイトの公開や、cssやJavaScript、画像ファイルなどを直接オブジェクトストレージへ取得しにいくこともできます。
4.オブジェクトストレージのアーキテクチャ  オブジェクトストレージとひとまとめにいっても、製品によってその実現方法は様々で異なります。
しかし、ここでは一例として利用されるアーキテクチャについて紹介します。
※ここで紹介するアーキテクチャがオブジェクトストレージのすべてのアーキテクチャを表すものではありません。また、わかりやすくするためかなり簡略化して記載しています。</description>
    </item>
    
    <item>
      <title>参加してきた、MSPJマイグレーションコンペ2017winter</title>
      <link>https://blog.mosuke.tech/entry/2017/02/20/184220/</link>
      <pubDate>Mon, 20 Feb 2017 18:42:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/02/20/184220/</guid>
      <description>先日、2017年2月18日に「MSPJマイグレーションコンペティション2017winter」に参加してきた。
MSPJマイグレーションコンペティション2017winterとは、
日本MSP協会コンペティショングループが主催する、 次代を担う若手運用技術者同士の交流・競争を通して日本のMSP事業者における運用技術の向上を目指したコンペティション。
もう少し平たく言うと、MSP事業者の本当の業務に近い形でのコンペを通じて、スキルアップを図りましょうというものだ。
自分はMSPの人じゃないけど参加は全然できた。
connpass.com
競技ルール 今回の競技のお題は、
「AWS上で動作しているレガシーなRedmineをAzure上に移行する」というものだ。
このコンペの特徴としては、実際にMSPでの業務に則し、お客さんから曖昧な要望を受けている部分や、
お客さん側にしかない権限については、お客さんと調整する必要があること。
例えば、環境の移行する際にはDNSの切り替えが必要だったのですが、DNSの設定権限は我々にはなくて、
Slackを利用して、DNS設定変更依頼や作業周知を出さなければいけなかった。
このあたりはとてもユニークなポイント。
お客さんからは移行について以下のような曖昧な要望をもらっていた。
&amp;lt;要望&amp;gt; - 今の環境を新しい環境に完全移行して欲しいです。 - 実施した内容と結果については報告が欲しいです。 - システムを止めるときは利用者に告知が必要なので連絡が欲しいです。 - 昔から使っている古い環境なので、バージョンアップして欲しいです。 - できれば利用者に影響を出さないように切り替えたいです。 - できればサーバに関する資料があるとありがたいです。 - できれば今はまったくバックアップを取っていないのでバックアップを取れるようにしたいです - できれば今後は利用者が増えるのでシステムを冗長化したいです。 - できれば新しいインフラエンジニアに引継ぎするために必要な情報がまとまっていると嬉しいです。 &amp;lt;担当者のコメント&amp;gt; - 前任のインフラエンジニアが辞めちゃったのでこのシステムもう分かる人がいなくって。 - 結構前から使っているので環境も古くなっているみたいで、OSのサポートがもうすぐ切れるって話を聞いたものですから、セキュリティとか色々心配で何とかしたいんです。 - みんなこのシステムを結構便利に使っていてくれているようだから、システムを切り替えるときは連絡しないとなぁ。 - そうそう、近々新しいインフラエンジニアが入社予定だから、その方に引き継げるようになっていると嬉しいですね。  ちなみにチームについては、当日の参加者で適当に3人チームを作って行った。
一緒の参加者が同じチームにならないように調整された。
構成把握 開始後、まずやったことが環境・構成の把握。
ざっと下記のような感じ。ログインしてすぐに、pstree みて大体の構成を把握した。
 インフラ: AWS(EC2) OS: CentOS5.2 Webサーバ: Apache2.0 + Passenger DB: MySQL5.1  Ruby: 1.9  Redmine: 2.3  DNS; Route53で管理。権限はお客さんのみ サーバ構成: サーバ1台のシングル構成  移行作戦 細かなバージョンはおいておいて、最終的に目指す構成は下記のようにした。</description>
    </item>
    
    <item>
      <title>Cookpad TechConf2017にいってきたメモ</title>
      <link>https://blog.mosuke.tech/entry/2017/01/23/233756/</link>
      <pubDate>Mon, 23 Jan 2017 23:37:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/01/23/233756/</guid>
      <description>はじめに
CookpadTechConf2017に参加してきた。
昨年は抽選に外れていけなかったのでよかった。
techconf.cookpad.com
おなじみCookpadが年に一回行っているテクノロジーカンファレンス。
１年間のクックパッドでの取り組みを発表する場。
完全メモ書きではあるが、ご活用ください。
 クックパッドの取り組み セッションはたくさんあったが、クックパッドが今年１年間で取り組んできた大きな内容は以下３つと感じた。
 海外進出  機械学習への取り組み スケールへの対応  海外進出の話は今まではほとんど聞いたことなかったので、本格的に力を入れ始めたというところだろう。
機械学習への取り組みは去年からと明確にいっていたのでこちらもそう。
最後のスケールへの対応は今までもたくさん発表してきたが、そこに大きな波がもう１つやってきた。後ほど。
海外進出 Go Global  宗教、言語、気候によってサービスを変える  同じ言語圏であっても気候が違えば違う食文化がある 例えばスペイン語圏でも、スペインと南米では全く食文化が異なる   どうやってサービスを作っていくか  あたりまえ品質 グローバリゼーションとローカライゼーション   検索のローカライズははてしなくどろくさい 翻訳もとんでもなく大変   Amazonの例だが、Kindleで&#34;OR&#34;で誤訳があった  「あるいは」のorなのか、「オレゴン州」のorなのか   プレミアムという言葉も実は難しい  プレミアムというのは地方によってはプレミアムでないものを差別する用語として使われることもある プライムやプレミアム、エクストリームなど使い分ける     国際チームは国籍がみんなばらばら  それぞれの考え方も文化も異なる 最終的なアウトプットだけ共有しあとはまかせるというスタイルをとっている    Global Infrastracture  多くのリージョンへ展開している  Choose your Country - Cookpad でも中国は進出してない   クックパッドはAWS絶対 中国市場ではやっぱり厳しさがあるようにみえる     グローバルアプリはスクラッチで新規開発  いまは普通のRailsアプリ 日本のCookpadとはUIも全く異なる   グローバルのインフラについて   us-east-1のサーバを利用 データベースはAurora for MySQL  Elasticache利用 nginx, unicornの構成 CDNはFastly   地域によってトラフィックピークが全く異なる  日本だとバレンタインシーズン  イスラムではラマダンと呼ばれるシーズンがある  しばらく断食していたその後に食事を楽しむ時期      Go Global - #CookpadTechconf 2017 // Speaker Deck</description>
    </item>
    
    <item>
      <title>クラウド上でのWordPressのスケールアウトを考える</title>
      <link>https://blog.mosuke.tech/entry/2017/01/04/223544/</link>
      <pubDate>Wed, 04 Jan 2017 22:35:00 +0900</pubDate>
      
      <guid>https://blog.mosuke.tech/entry/2017/01/04/223544/</guid>
      <description>複数台サーバでのWordPressの構築・運用について考える。
実際に、とあるクラウドで分散環境のWordPressを構築したのでその知見をまとめる。
なるべく特定のクラウドに特価しないものとして記載したい。
やりたいこと  スケールアウトできるWordPress環境を作る  SSLに対応する HTTP/2に対応する  AWSなどのクラウド環境で構築する  アーキテクチャ まず先に全体のアーキテクチャ図から示す。
これから各項目について解説していく。

 SSL・HTTP/2への対応 まずSSLへの対応だが、通常ならばロードバランサをSSLの終端とし下記のような構成にすることが多いだろう。
この場合はロードバランサをL7のものとして稼働させる。

しかし、HTTP/2に対応しようと思うと事情は異なってくる。
（もちろん、最近ではAWSのALBのようにHTTP/2に対応する製品がでてきているのは承知だが。）
現在のパブリッククラウドで利用できるロードバランサの多くはまだHTTP/2に対応していない。
そのため、ロードバランサをL4として稼働させ、配下のWebサーバにてHTTP/2を処理する必要がでてくる。
この場合、ロードバランサはTCPでポート443を待ち受けるようにし、配下のWebサーバへポート443のままでフォワードすればいい。

クラウド環境ではWebサーバがスケールすることは前提にいれることがおおい。
そのため、この場合のSSL証明書はN台に対応した製品を買う必要がある。
例えば以下のような製品など。
 SureServer for クラウド｜Cybertrust.ne.jp  データベースの分離 分散環境でのWordpressでは共通したコンテンツを配信するため、データベースはもちろんWebサーバとは分離したほうがいい。
それぞれのWebサーバは共通のデータベースを見に行くべきだ。
データベースを自前で冗長化しても構わないが、それなりの運用コストがかかることは容易に想像がつくので、
クラウドのマネージドデータベースサービスを利用した。
 Amazon RDS（クラウドでのリレーショナルデータベースサービス） | AWS ApsaraDB for RDS - データベースホスティング | Alibaba Cloud  管理画面 管理画面のみを分離するアーキテクチャも考えられるが、ここではそうしないこととする。
管理画面へのログインセッションの保持は、別途KVS(RedisやMemcached)に保存してもいいと思う。
ですが、WordPress4.0以降ではデフォルトではMySQLへセッションを保存するので必須の対応ではないといえる。
github.com
記事で使うアップロード画像などの対応 管理画面から記事を投稿するとする。
記事のデータはデータベースに保存されるためどのWebサーバからも記事を参照できる。
しかし、記事に含まれる画像データはどうだろうか。
通常のWordpressでは管理画面サーバの/wp-content/uploads以下に画像を保存する。
複数台Webサーバがある状態で、たまたまアクセスしているサーバに画像を保存しても、他のサーバからは参照することができない。
これに対するソリューションはいくつかあるだろう。
例えば、rsyncなどを使って他のサーバと画像ファイルを同期するとか、画像用のストレージを用意しNFSで参照するとか。
冗長化の観点からもここはオブジェクトストレージのサービスを利用するのがいいだろう。
例えば、下記のような製品だ。</description>
    </item>
    
  </channel>
</rss>